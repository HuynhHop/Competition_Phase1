# Competition Phase 1


# Kết quả thu được đã được mô tả VÀ đánh giá trong code
NHÓM CHÚNG EM CHỌN MÔ HÌNH RANDOM FOREST TRONG 4 MÔ HÌNH TRAIN VÌ MÔ HÌNH NÀY CHO KẾT QUẢ ĐỘ CHÍNH XÁC CAO VÀ ĐÚNG ĐẮN NHẤT


# DƯỚI ĐÂY LÀ CODE CỤ THỂ
# I. Cài đặt mô hình với tập train
### 1. Cài đặt thư viện
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
# from sklearn.metrics import plot_confusion_matrix
### 2. Tìm hiểu về dữ liệu
data = pd.read_csv("train.csv", sep="|")
### 3. Khám phá tổng quan về dữ liệu
data.head()
# Loại bỏ các giá trị bị thiếu (NA)
heart_dropna = data.dropna()
print(data.columns)
print(data.head())
data.columns = data.columns.str.strip()  # Loại bỏ dấu cách ở đầu và cuối tên cột

# Chia dữ liệu thành features và target
X = data.drop(columns=['fraud'])
y = data['fraud']
# Chuyển các biến categorical sang dạng one-hot
oh_X = pd.get_dummies(X, drop_first = True)
oh_X.head()
oh_X.info()
### 4. Chia dữ liệu
Ta chia tỉ lệ tập train và tập test là 70/30
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    oh_X, y, test_size = 0.3, random_state = 1)

print('Labels counts in y:', len(y))
print('Labels counts in y_train:', len(y_train))
print('Labels counts in y_test:', len(y_test))
### 5. Tạo một Random Forest với sklearn
model = RandomForestClassifier(n_estimators=100, random_state=1)
model.fit(X_train, y_train)
### 5.1. Độ đo
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Dự đoán nhãn của dữ liệu kiểm tra
y_pred = model.predict(X_test)

# Tính toán các độ đo
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# In các độ đo
print("Accuracy on test set:", accuracy)
print("Precision on test set:", precision)
print("Recall on test set:", recall)
print("F1 score on test set:", f1)

### 6. Vẽ sơ đồ Confusion Matrix
from sklearn.metrics import confusion_matrix
import seaborn as sns

# Dự đoán nhãn của dữ liệu validation
y_pred = model.predict(X_test)

# Tính ma trận nhầm lẫn
cm = confusion_matrix(y_test, y_pred)

# Vẽ ma trận nhầm lẫn
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title("Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()
### Dự đoán:
- 527 người: Dự đoán không gian lận là đúng 
- 2   người: Dự đoán gian lận, thực chất là không gian lận
- 15  người: Dự đoán không gian lận, thực chất là gian lận
- 20  người: Dự đoán gian lận là đúng
# SỬ DỤNG MÔ HÌNH LOGISTIC REGRESSTION
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import precision_recall_curve, auc
import matplotlib.pyplot as plt

# Huấn luyện mô hình Logistic Regression
logistic_model = LogisticRegression(random_state=1)
logistic_model.fit(X_train, y_train)

# Dự đoán xác suất của lớp positive từ mô hình Logistic Regression
y_prob_logistic = logistic_model.predict_proba(X_test)[:, 1]

# Tính precision, recall và ngưỡng (thresholds) cho mô hình Logistic Regression
precision_logistic, recall_logistic, thresholds_logistic = precision_recall_curve(y_test, y_prob_logistic)

# Tính diện tích dưới đường cong Precision-Recall (AUC) cho mô hình Logistic Regression
pr_auc_logistic = auc(recall_logistic, precision_logistic)

print("Precision:", precision_logistic)
print("Recall:", recall_logistic)
print("Thresholds:", thresholds_logistic)
# Vẽ Precision-Recall curve cho mô hình Logistic Regression
plt.figure(figsize=(8, 6))
plt.plot(recall_logistic, precision_logistic, color='blue', lw=2, label=f'Precision-Recall Curve (AUC = {pr_auc_logistic:.2f})')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve for Logistic Regression')
plt.legend(loc='lower left')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.grid(True)
plt.show()
### AUC chỉ đạt 0,51
Cho thấy mô hình này chỉ hơi tốt so với một mô hình ngẫu nhiên

# SỬ DỤNG MÔ HÌNH SVM
from sklearn.svm import SVC

# Huấn luyện mô hình SVM
svm_model = SVC(kernel='linear', probability=True, random_state=1)
svm_model.fit(X_train, y_train)

# Dự đoán nhãn của dữ liệu kiểm tra
y_pred_svm = svm_model.predict(X_test)

# Lấy ra các giá trị dự đoán từ hàm decision_function của SVM
decision_values_svm = svm_model.decision_function(X_test)

# Vẽ biểu đồ scatter plot cho SVM
plt.figure(figsize=(8, 6))
plt.scatter(range(len(decision_values_svm)), decision_values_svm, c=y_pred_svm, cmap='coolwarm', alpha=0.7)
plt.xlabel('Sample Index')
plt.ylabel('Decision Function Value')
plt.title('Decision Function Values for SVM Predictions')
plt.colorbar(label='Predicted Class')
plt.grid(True)
plt.show()
## Ta quan sát thấy khoảng 30 điểm positive
Tức là hành vi gian lận
Với mô hình này độ chính xác khá cao, khi chỉ có một số ít điểm nằm rời rạt
# SỬ DỤNG MÔ HÌNH NEURAL NETWORKS
from sklearn.neural_network import MLPClassifier

# Huấn luyện mô hình Neural Networks
nn_model = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=1)
nn_model.fit(X_train, y_train)

# Dự đoán nhãn của dữ liệu kiểm tra
y_pred_nn = nn_model.predict(X_test)

# Lấy ra các giá trị dự đoán từ hàm predict_proba của Neural Networks
predicted_probabilities_nn = nn_model.predict_proba(X_test)

# Vẽ biểu đồ scatter plot cho Neural Networks
plt.figure(figsize=(8, 6))
plt.scatter(range(len(predicted_probabilities_nn)), predicted_probabilities_nn[:, 1], c=y_pred_nn, cmap='coolwarm', alpha=0.7)
plt.xlabel('Sample Index')
plt.ylabel('Predicted Probability for Class 1')
plt.title('Predicted Probabilities for Class 1 (Neural Networks)')
plt.colorbar(label='Predicted Class')
plt.grid(True)
plt.show()

## Mô hình này rất tốt, độ chính xác khá cao
# II. Chạy mô hình với tập test (phase2)